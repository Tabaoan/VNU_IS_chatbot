# ===================== IMPORTS =====================
import os, re
from typing import Dict, Any, List

from dotenv import load_dotenv
load_dotenv(override=True)

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_pinecone import Pinecone
from pinecone import Pinecone as PineconeClient
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage

from langdetect import detect


# ===================== ENV =====================
OPENAI__API_KEY = os.getenv("OPENAI__API_KEY")
OPENAI__EMBEDDING_MODEL = os.getenv("OPENAI__EMBEDDING_MODEL")
OPENAI__MODEL_NAME = os.getenv("OPENAI__MODEL_NAME")
OPENAI__TEMPERATURE = os.getenv("OPENAI__TEMPERATURE")

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")
EMBEDDING_DIM = 3072


LANG_MODEL_API_KEY = os.getenv("LANG_MODEL_API_KEY")
# ===================== INIT LLM =====================
llm = ChatOpenAI(
    api_key=OPENAI__API_KEY,
    model_name=OPENAI__MODEL_NAME,
    temperature=float(OPENAI__TEMPERATURE) if OPENAI__TEMPERATURE else 0
)
lang_llm = ChatOpenAI(
    api_key=LANG_MODEL_API_KEY,
    model_name="gpt-4o-mini",
    temperature=0
)
# Khá»Ÿi táº¡o Pinecone Client (Serverless API)
if PINECONE_API_KEY:
    pc = PineconeClient(api_key=PINECONE_API_KEY)
else:
    pc = None
    print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y PINECONE_API_KEY. Pinecone sáº½ khÃ´ng hoáº¡t Ä‘á»™ng.")

emb = OpenAIEmbeddings(api_key=OPENAI__API_KEY, model=OPENAI__EMBEDDING_MODEL)

vectordb = None
retriever = None


# ===================== SYSTEM PROMPT (ÄÃƒ RÃšT Gá»ŒN) =====================
PDF_READER_SYS = (
    "Báº¡n lÃ  má»™t trá»£ lÃ½ AI cÃ³ nhiá»‡m vá»¥ trÃ­ch xuáº¥t vÃ  tráº£ lá»i thÃ´ng tin dá»±a trÃªn ná»™i dung tÃ i liá»‡u. "
    "LuÃ´n tuÃ¢n thá»§ cÃ¡c nguyÃªn táº¯c sau:\n\n"
    "1. Chá»‰ tráº£ lá»i dá»±a trÃªn ná»™i dung cÃ³ trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p (context).\n"
    "2. Náº¿u thÃ´ng tin khÃ´ng cÃ³ trong tÃ i liá»‡u, hÃ£y nÃ³i rÃµ ráº±ng tÃ i liá»‡u khÃ´ng chá»©a thÃ´ng tin liÃªn quan.\n"
    "3. Náº¿u tÃ i liá»‡u cÃ³ thÃ´ng tin, pháº£i tráº£ lá»i Ä‘áº§y Ä‘á»§ vÃ  chÃ­nh xÃ¡c theo Ä‘Ãºng ná»™i dung Ä‘Ã³.\n"
    "4. KhÃ´ng Ä‘Æ°á»£c tá»± suy diá»…n hoáº·c thÃªm kiáº¿n thá»©c bÃªn ngoÃ i.\n"
    "5. LuÃ´n tráº£ lá»i báº±ng Ä‘Ãºng ngÃ´n ngá»¯ mÃ  ngÆ°á»i dÃ¹ng sá»­ dá»¥ng.\n"
    "6. VÄƒn phong rÃµ rÃ ng, trung láº­p.\n"
    "7. TrÃ¡nh sá»­ dá»¥ng cÃ¡c cá»¥m tá»« nhÆ° 'Dá»±a trÃªn tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p' trong cÃ¢u tráº£ lá»i.\n"
    "8. Tráº£ lá»i theo Ä‘Ãºng ngÃ´n ngá»¯ cá»§a ngÆ°á»i dÃ¹ng nháº­p vÃ o.\n"
)

# ===================== LANGUAGE UTILS =====================
# ğŸ”µ NEW: PhÃ¡t hiá»‡n ngÃ´n ngá»¯ báº±ng OpenAI
def detect_language_openai(text: str) -> str:
    try:
        res = lang_llm.invoke([
            SystemMessage(content=(
                "Báº¡n lÃ  module phÃ¡t hiá»‡n ngÃ´n ngá»¯. "
                "Chá»‰ tráº£ vá» mÃ£ ISO-639-1 nhÆ°: vi, en, ja, ko, zh, fr, es. "
                "KhÃ´ng giáº£i thÃ­ch thÃªm."
            )),
            HumanMessage(content=text)
        ]).content
        return res.strip().lower()
    except:
        return "vi"


# ğŸ”µ NEW: Dá»‹ch output Ä‘Ãºng ngÃ´n ngá»¯ ngÆ°á»i dÃ¹ng
def convert_language(text: str, target_lang: str) -> str:

    lang_mapping = {
        "vi": "Vietnamese",
        "en": "English",
        "ko": "Korean",
        "ja": "Japanese",
        "zh": "Chinese",
        "fr": "French",
        "es": "Spanish",
        "de": "German",
        "th": "Thai"
    }
    target_lang_name = lang_mapping.get(target_lang, target_lang)

    try:
        translated = lang_llm.invoke([
            SystemMessage(content="Báº¡n lÃ  má»™t phiÃªn dá»‹ch chuyÃªn nghiá»‡p. Chá»‰ tráº£ vá» báº£n dá»‹ch."),
            HumanMessage(
                content=f"Dá»‹ch Ä‘oáº¡n vÄƒn sau sang {target_lang_name} ({target_lang}):\n{text}"
            )
        ]).content
        return translated.strip()
    except:
        return text

# ===================== VECTORDB UTILS =====================
def _list_index_names() -> List[str]:
    """
    Tráº£ vá» danh sÃ¡ch tÃªn index tá»« Pinecone, há»— trá»£ nhiá»u dáº¡ng tráº£ vá»
    cá»§a cÃ¡c version client khÃ¡c nhau.
    """
    if pc is None:
        return []
    try:
        res = pc.list_indexes()
        # Má»™t sá»‘ version tráº£ vá» object cÃ³ .names()
        if hasattr(res, "names"):
            return list(res.names())
        # Docs má»›i: tráº£ vá» list[dict] hoáº·c dict{'indexes': [...]}
        if isinstance(res, dict) and "indexes" in res:
            return [idx.get("name") for idx in res["indexes"] if "name" in idx]
        if isinstance(res, list):
            names = []
            for idx in res:
                if isinstance(idx, dict) and "name" in idx:
                    names.append(idx["name"])
                elif isinstance(idx, str):
                    names.append(idx)
            return names
        return []
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi list_indexes: {e}")
        return []


def build_context_from_hits(hits, max_chars: int = 6000) -> str:
    ctx = []
    total = 0
    for h in hits:
        source = h.metadata.get('source', 'unknown')
        seg = f"[Nguá»“n: {source}]\n{h.page_content.strip()}"
        if total + len(seg) > max_chars:
            break
        ctx.append(seg)
        total += len(seg)
    return "\n\n".join(ctx)


def load_vectordb():
    """Load Pinecone index (dÃ¹ng cho cáº£ CLI vÃ  server)."""
    global vectordb, retriever, pc

    if pc is None or not PINECONE_INDEX_NAME:
        print("âŒ Pinecone client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o hoáº·c thiáº¿u PINECONE_INDEX_NAME.")
        return None

    try:
        index_names = _list_index_names()
        if PINECONE_INDEX_NAME not in index_names:
            print(f"âŒ Index '{PINECONE_INDEX_NAME}' khÃ´ng tá»“n táº¡i trong Pinecone.")
            return None

        index = pc.Index(PINECONE_INDEX_NAME)
        stats = index.describe_index_stats()

        if stats.get("total_vector_count", 0) == 0:
            print("âŒ Index khÃ´ng chá»©a document nÃ o.")
            return None

        vectordb = Pinecone(index=index, embedding=emb, text_key="text")
        retriever = vectordb.as_retriever(search_kwargs={"k": 15})
        print(f" VectorDB loaded: {PINECONE_INDEX_NAME} vá»›i {stats.get('total_vector_count', 0)} vectors")
        return vectordb

    except Exception as e:
        print(f" Lá»—i load vectordb: {e}")
        return None


def check_vectordb_exists() -> bool:
    """
    HÃ m nÃ y Ä‘Æ°á»£c Flask dÃ¹ng trong /api/status.
    Tá»± Ä‘á»™ng load vectordb náº¿u chÆ°a cÃ³.
    """
    global vectordb, retriever

    if pc is None or not PINECONE_INDEX_NAME:
        return False

    try:
        index_names = _list_index_names()
        if PINECONE_INDEX_NAME not in index_names:
            return False

        index = pc.Index(PINECONE_INDEX_NAME)
        stats = index.describe_index_stats()
        if stats.get("total_vector_count", 0) == 0:
            return False

        # Náº¿u retriever chÆ°a khá»Ÿi táº¡o thÃ¬ khá»Ÿi táº¡o
        if retriever is None:
            vectordb = Pinecone(index=index, embedding=emb, text_key="text")
            retriever = vectordb.as_retriever(search_kwargs={"k": 15})

        return True
    except Exception as e:
        print(f"âš ï¸ Lá»—i check_vectordb_exists: {e}")
        return False


def get_vectordb_stats():
    """
    DÃ¹ng cho API /api/status trÃªn Flask server.
    """
    if pc is None or not PINECONE_INDEX_NAME:
        return {"exists": False, "total_documents": 0}

    index_names = _list_index_names()
    if PINECONE_INDEX_NAME not in index_names:
        return {"exists": False, "total_documents": 0}

    try:
        index = pc.Index(PINECONE_INDEX_NAME)
        stats = index.describe_index_stats()
        return {
            "exists": True,
            "name": PINECONE_INDEX_NAME,
            "total_documents": stats.get("total_vector_count", 0),
            "dimension": stats.get("dimension", EMBEDDING_DIM)
        }
    except Exception as e:
        print(f"âš ï¸ Lá»—i get_vectordb_stats: {e}")
        return {"exists": False, "total_documents": 0}


# ===================== CLEANING =====================
_URL_RE = re.compile(r"https?://[^\s]+", re.IGNORECASE)


def clean_question_remove_uris(text: str) -> str:
    txt = _URL_RE.sub(" ", text or "")
    toks = re.split(r"\s+", txt)
    toks = [t for t in toks if not t.lower().endswith(".pdf")]
    return " ".join(toks).strip()


def convert_language(text: str, target_lang: str) -> str:
    try:
        translated = llm.invoke([
            SystemMessage(content="HÃ£y dá»‹ch chÃ­nh xÃ¡c Ä‘oáº¡n vÄƒn sang ngÃ´n ngá»¯ Ä‘Æ°á»£c yÃªu cáº§u."),
            HumanMessage(content=f"Dá»‹ch sang {target_lang}. Chá»‰ tráº£ vá» báº£n dá»‹ch:\n{text}")
        ]).content
        return translated.strip()
    except:
        return text


# ===================== PROCESS QUESTION =====================
def process_pdf_question(i: Dict[str, Any]) -> str:
    global retriever

    message = i["message"]
    history = i.get("history", [])

    clean_question = clean_question_remove_uris(message)

    # ğŸ”µ NEW: Detect ngÃ´n ngá»¯ báº±ng OpenAI
    try:
        user_lang = detect_language_openai(message)
    except:
        user_lang = "vi"

    # Náº¿u retriever chÆ°a khá»Ÿi táº¡o
    if retriever is None:
        load_vectordb()

    if retriever is None:
        err = "VectorDB chÆ°a Ä‘Æ°á»£c load hoáº·c khÃ´ng cÃ³ dá»¯ liá»‡u."
        return convert_language(err, user_lang)

    # ğŸ” Query VectorDB
    try:
        hits = retriever.invoke(clean_question)
        if not hits:
            msg = "TÃ i liá»‡u khÃ´ng chá»©a thÃ´ng tin liÃªn quan."
            return convert_language(msg, user_lang)

        context = build_context_from_hits(hits)

        # System prompt kÃ¨m ngÃ´n ngá»¯
        system_msg = (
            PDF_READER_SYS +
            f"\n\nNgÆ°á»i dÃ¹ng Ä‘ang dÃ¹ng ngÃ´n ngá»¯: {user_lang}."
        )

        messages = [SystemMessage(content=system_msg)]

        if history:
            messages.extend(history[-10:])

        # User message gá»­i vÃ o LLM
        user_message = (
            f"CÃ¢u há»i: {clean_question}\n\n"
            f"Context:\n{context}\n\n"
            f"HÃ£y tráº£ lá»i dá»±a trÃªn context vÃ  báº±ng ngÃ´n ngá»¯: {user_lang}."
        )
        messages.append(HumanMessage(content=user_message))

        # ğŸ§  LLM tráº£ lá»i
        response = llm.invoke(messages).content

        # ğŸ”µ NEW: Náº¿u output khÃ´ng Ä‘Ãºng ngÃ´n ngá»¯ â†’ dá»‹ch láº¡i
        detected_out_lang = detect_language_openai(response)
        if detected_out_lang != user_lang:
            response = convert_language(response, user_lang)

        return response

    except Exception as e:
        msg = f"Lá»—i xá»­ lÃ½: {str(e)}"
        return convert_language(msg, user_lang)


# ===================== CHATBOT WRAPPER =====================
pdf_chain = RunnableLambda(process_pdf_question)
store: Dict[str, ChatMessageHistory] = {}


def get_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


chatbot = RunnableWithMessageHistory(
    pdf_chain,
    get_history,
    input_messages_key="message",
    history_messages_key="history"
)


# ===================== Tá»° Äá»˜NG LOAD KHI DÃ™NG Vá»šI SERVER =====================
# Khi file nÃ y Ä‘Æ°á»£c import bá»Ÿi Flask, Ä‘oáº¡n dÆ°á»›i sáº½ cháº¡y má»™t láº§n
if pc is not None and PINECONE_INDEX_NAME:
    print("ğŸ“¥ Auto-loading Pinecone Index cho server...")
    load_vectordb()
else:
    print("âš ï¸ Pinecone chÆ°a cáº¥u hÃ¬nh Ä‘áº§y Ä‘á»§, VectorDB sáº½ khÃ´ng hoáº¡t Ä‘á»™ng.")


# ===================== CLI HELPERS (TÃ™Y CHá»ŒN) =====================
def print_help():
    print("\n" + "=" * 60)
    print("ğŸ“š CÃC Lá»†NH CÃ“ Sáº´N:")
    print("=" * 60)
    print(" - exit / quit  : ThoÃ¡t chÆ°Æ¡ng trÃ¬nh")
    print(" - clear        : XÃ³a lá»‹ch sá»­ há»™i thoáº¡i")
    print(" - status       : Kiá»ƒm tra tráº¡ng thÃ¡i Pinecone Index")
    print(" - help         : Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n nÃ y")
    print("=" * 60 + "\n")


def handle_command(command: str, session: str) -> bool:
    cmd = command.lower().strip()

    if cmd in {"exit", "quit"}:
        print("\nğŸ‘‹ Táº¡m biá»‡t!")
        return False

    elif cmd == "clear":
        if session in store:
            store[session].clear()
            print("ğŸ§¹ ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i.\n")
        return True

    elif cmd == "status":
        stats = get_vectordb_stats()
        print("\n" + "=" * 60)
        print("ğŸ“Š TRáº NG THÃI PINECONE INDEX")
        print("=" * 60)
        if stats["exists"]:
            print(f"âœ… Index: {stats['name']}")
            print(f"ğŸ“š Tá»•ng documents: {stats['total_documents']}")
        else:
            print("âŒ Index khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng cÃ³ dá»¯ liá»‡u.")
        print("=" * 60 + "\n")
        return True

    elif cmd == "help":
        print_help()
        return True

    return True


# ===================== MAIN (CHáº Y CLI, KHÃ”NG áº¢NH HÆ¯á»NG SERVER) =====================
if __name__ == "__main__":
    session = "pdf_reader_session"

    if not all([OPENAI__API_KEY, PINECONE_API_KEY, PINECONE_INDEX_NAME]):
        print("âŒ Thiáº¿u biáº¿n mÃ´i trÆ°á»ng.")
        exit(1)

    print("\n" + "=" * 80)
    print("ğŸ¤– CHATBOT TÃ€I LIá»†U (VECTOR + LLM)")
    print("=" * 80)
    print_help()

    print("ğŸ“¥ Äang load Pinecone Index...")
    result = load_vectordb()

    if result is None:
        print("âŒ KhÃ´ng thá»ƒ load Pinecone Index.")
        exit(1)

    stats = get_vectordb_stats()
    print(f"âœ… Pinecone sáºµn sÃ ng vá»›i {stats['total_documents']} documents\n")
    print("ğŸ’¬ Sáºµn sÃ ng tráº£ lá»i cÃ¢u há»i!\n")

    while True:
        try:
            message = input("ğŸ‘¤ Báº¡n: ").strip()
            if not message:
                continue

            if not handle_command(message, session):
                break

            # Náº¿u lÃ  lá»‡nh, khÃ´ng xá»­ lÃ½ tiáº¿p
            if message.lower() in ["clear", "status", "help"]:
                continue

            print("ğŸ” Äang tÃ¬m kiáº¿m trong Pinecone...")

            response = chatbot.invoke(
                {"message": message},
                config={"configurable": {"session_id": session}}
            )

            print(f"\nğŸ¤– Bot: {response}\n")
            print("-" * 80 + "\n")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Táº¡m biá»‡t!")
            break

        except Exception as e:
            print(f"\nâŒ Lá»—i: {e}\n")
